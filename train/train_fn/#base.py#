from __future__ import print_function

import time
import numpy as np
import torch
import torch.nn as nn

from aug.cutmix import *

from utils.accuracy import AverageMeter
from utils.common import Bar

import copy, time

from datasets.cifar100 import test_CIFAR100
import random



def update_score_base(loader, model, n_samples_per_class, posthoc_la, num_test, accept_rate):
    model.eval()
    
    if posthoc_la:
        dist = torch.tensor(n_samples_per_class)
        prob = dist / dist.sum()
    
    # curr_state = loader.dataset.curr_state
    # max_state = torch.max(curr_state).int() + 1
    
    with torch.no_grad():

        n = num_test
        pos, state = [], []
        for cidx in range(len(n_samples_per_class)):
            class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]
            max_state = loader.dataset.curr_state[class_pos[0]].int() 
            for s in range(max_state+1):
                _pos = random.choices(class_pos.tolist(), k = n * (s+1))
                pos += _pos 
                state += [s] * len(_pos)
 
        tmp_dataset = test_CIFAR100(pos, state, loader.dataset)
        tmp_loader = torch.utils.data.DataLoader(tmp_dataset, batch_size = 128, shuffle=False, num_workers=8)
        

        for batch_idx, data_tuple in enumerate(tmp_loader):
            data = data_tuple[0].cuda()
            label = data_tuple[1]
            idx = data_tuple[2]
            state = data_tuple[3]

            logit = model(data, output_type = None).cpu()

            if posthoc_la:
                logit = logit.cpu() - torch.log(prob.view(1, -1).expand(logit.shape[0],-1))

            correct = (logit.max(dim=1)[1] == label).int().detach().cpu()
            loader.dataset.update_scores(correct,idx, state)

    

    # loader.dataset.update()
    correct_sum_per_class = torch.zeros(len(n_samples_per_class))
    trial_sum_per_class = torch.zeros(len(n_samples_per_class))
    for cidx in range(len(n_samples_per_class)):
        class_pos = torch.where(torch.tensor(loader.dataset.targets) == cidx)[0]
        
        correct_sum_row = torch.sum(loader.dataset.score_tmp[class_pos], dim=0)
        trial_sum_row = torch.sum(loader.dataset.num_test[class_pos], dim=0)


        ratio = correct_sum_row / trial_sum_row 
        idx = loader.dataset.curr_state[class_pos][0].int() + 1
        condition = torch.sum((ratio[:idx] > accept_rate)) == idx 
        
        # if correct_sum == trial_sum:
        # if float(correct_sum) >= float(trial_sum * 0.6):
        if condition:
            loader.dataset.curr_state[class_pos] += 1
        else:
            loader.dataset.curr_state[class_pos] -= 1

        

    loader.dataset.curr_state = loader.dataset.curr_state.clamp(loader.dataset.min_state, loader.dataset.max_state-1)
    loader.dataset.score_tmp *= 0
    loader.dataset.num_test *= 0


    # print(f'Max correct: {int(torch.max(correct_sum_per_class))} Max trial: {int(torch.max(trial_sum_per_class))}')
    
    # loader.dataset.update()
    model.train()
    
    # Debug
    curr_state = loader.dataset.curr_state
    label = loader.dataset.targets
    print(f'Max state: {int(torch.max(curr_state))} // Min state: {int(torch.min(curr_state))}')

    return curr_state, label

def train_base(args, trainloader, model, optimizer, criterion, epoch, weighted_trainloader, teacher = None):
    model.train()
    
    batch_time = AverageMeter()
    data_time = AverageMeter()
    losses = AverageMeter()
    end = time.time()
    
    # cls_num need to get
    cls_num = trainloader.dataset.cls_num
    # correct_all = torch.zeros(cls_num).int()
    output = []
    targets = []

    bar = Bar('Training', max=len(trainloader))

    if args.cmo and 3 < epoch < (args.epochs - 3):
        inverse_iter = iter(weighted_trainloader)

    for batch_idx, data_tuple in enumerate(trainloader):
        inputs_b = data_tuple[0]
        targets_b = data_tuple[1]
        indexs = data_tuple[2]
        targets += targets_b.tolist()


        # Measure data loading
        data_time.update(time.time() - end)
        batch_size = targets_b.size(0)
        
        if args.cmo and 3 < epoch < (args.epochs - 3):
            try:
                data_tuple_f = next(inverse_iter)
            except:
                inverse_iter = iter(weighted_trainloader)
                data_tuple_f = next(inverse_iter)

            inputs_f = data_tuple_f[0]
            targets_f = data_tuple_f[1]
            inputs_f = inputs_f[:len(inputs_b)]
            targets_f = targets_f[:len(targets_b)]
            inputs_f = inputs_f.cuda(non_blocking=True)
            targets_f = targets_f.cuda(non_blocking=True)

        inputs_b = inputs_b.cuda(non_blocking=True)
        targets_b = targets_b.cuda(non_blocking=True)


        r = np.random.rand(1)
        if args.cmo and 3 < epoch < (args.epochs - 3) and r < 0.5:
            inputs_b, lam = cutmix(inputs_f, inputs_b)
            outputs = model(inputs_b, None)
            loss = criterion(outputs, targets_b, epoch) * lam + criterion(outputs, targets_f, epoch) * (1.-lam)
        else:
            outputs = model(inputs_b, None)
            loss = criterion(outputs, targets_b, epoch)
        
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # update 
        output += outputs.max(dim=1)[1].tolist()
        # correct = (outputs.max(dim=1)[1] == targets_b).int().detach().cpu()
        
        # record
        losses.update(loss.item(), targets_b.size(0))
        batch_time.update(time.time() - end)
        end = time.time()
        
        # plot
        bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | ' \
                      'Loss: {loss:.4f}'.format(
                    batch=batch_idx + 1,
                    size=len(trainloader),
                    data=data_time.avg,
                    bt=batch_time.avg,
                    total=bar.elapsed_td,
                    eta=bar.eta_td,
                    loss=losses.avg,
                    )
        bar.next()
    bar.finish()
    # print(targets)

    for cidx in range(cls_num):
        class_pos = torch.where(torch.tensor(targets) == cidx)[0]
        correct_all = (torch.tensor(output) == torch.tensor(targets))[class_pos].int().sum()
        if epoch > 50 and correct_all > trainloader.dataset.temp[cidx]:
            trainloader.dataset.aug_weight[cidx][trainloader.dataset.aug_choose[cidx]] += 1
            # if trainloader.dataset.aug_weight[cidx][trainloader.dataset.aug_choose[cidx]] > 10:
            #     trainloader.dataset.aug_weight[cidx][trainloader.dataset.aug_choose[cidx]] -= 1
        elif epoch > 50 and correct_all < trainloader.dataset.temp[cidx]:
            trainloader.dataset.aug_weight[cidx][trainloader.dataset.aug_choose[cidx]] -= 1
            if trainloader.dataset.aug_weight[cidx][trainloader.dataset.aug_choose[cidx]] < 1:
                trainloader.dataset.aug_weight[cidx][trainloader.dataset.aug_choose[cidx]] = 1
        trainloader.dataset.temp[cidx] = correct_all

    # for cidx in range(cls_num):
    #     class_pos = torch.where(torch.tensor(targets) == cidx)[0]
    #     correct_all = (torch.tensor(output) == torch.tensor(targets))[class_pos].int().sum()
    #     for i in range(3):
    #         if correct_all > trainloader.dataset.temp[cidx]:
    #             trainloader.dataset.aug_weight[cidx][trainloader.dataset.aug_choose[cidx][i]] += 1
    #             # if trainloader.dataset.aug_weight[cidx][trainloader.dataset.aug_choose[cidx]] > 10:
    #             #     trainloader.dataset.aug_weight[cidx][trainloader.dataset.aug_choose[cidx]] -= 1
    #         elif correct_all < trainloader.dataset.temp[cidx]:
    #             trainloader.dataset.aug_weight[cidx][trainloader.dataset.aug_choose[cidx][i]] -= 1
    #             if trainloader.dataset.aug_weight[cidx][trainloader.dataset.aug_choose[cidx][i]] < 1:
    #                 trainloader.dataset.aug_weight[cidx][trainloader.dataset.aug_choose[cidx][i]] = 1
    #     trainloader.dataset.temp[cidx] = correct_all
    return losses.avg
